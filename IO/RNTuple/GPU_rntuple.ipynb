{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2f83179-3173-4136-933b-25757ec5e874",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84f7538b-08ca-40dd-bb3f-cdac7df5f7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading column 1408\n",
      "Reading column 1442\n",
      "GPU decompression\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (7818,) into shape (977,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 351\u001b[0m\n\u001b[1;32m    349\u001b[0m cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJet_pt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    350\u001b[0m classname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 351\u001b[0m \u001b[43mkvikuproot_open_RNTuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_rntuple\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassname\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 286\u001b[0m, in \u001b[0;36mkvikuproot_open_RNTuple\u001b[0;34m(in_ntuple_path, columns, classname, entry_start, entry_stop)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU decompression\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    285\u001b[0m codec \u001b[38;5;241m=\u001b[39m NvCompBatchCodec(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 286\u001b[0m all_decompressed_content \u001b[38;5;241m=\u001b[39m \u001b[43mcodec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_compressed_buffers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mall_output_buffers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# Process decompressed data\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;66;03m# arrays = Process_decompressed_content(in_ntuple,\u001b[39;00m\n\u001b[1;32m    291\u001b[0m                                       \u001b[38;5;66;03m# target_cols,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m#                 elif delta:\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;66;03m#                     res = cp.cumsum(res)\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/kvikio-cuda12.5-py3.11/lib/python3.11/site-packages/kvikio/nvcomp_codec.py:216\u001b[0m, in \u001b[0;36mNvCompBatchCodec.decode_batch\u001b[0;34m(self, bufs, out)\u001b[0m\n\u001b[1;32m    214\u001b[0m o \u001b[38;5;241m=\u001b[39m ensure_contiguous_ndarray_like(out[i])\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(o, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__cuda_array_interface__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 216\u001b[0m     \u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopyto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mret\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mno\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     cp\u001b[38;5;241m.\u001b[39masnumpy(ret\u001b[38;5;241m.\u001b[39mview(dtype\u001b[38;5;241m=\u001b[39mo\u001b[38;5;241m.\u001b[39mdtype), out\u001b[38;5;241m=\u001b[39mo, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream)\n",
      "File \u001b[0;32m~/.conda/envs/kvikio-cuda12.5-py3.11/lib/python3.11/site-packages/cupy/_manipulation/basic.py:81\u001b[0m, in \u001b[0;36mcopyto\u001b[0;34m(dst, src, casting, where)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m src_is_scalar:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# Check broadcast condition\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;66;03m# - for fast-paths and\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;66;03m# - for a better error message (than ufunc's).\u001b[39;00m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;66;03m# NumPy allows stripping leading unit dimensions.\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m([\n\u001b[1;32m     77\u001b[0m         s \u001b[38;5;129;01min\u001b[39;00m (d, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m s, d \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mzip_longest(\n\u001b[1;32m     79\u001b[0m             \u001b[38;5;28mreversed\u001b[39m(src\u001b[38;5;241m.\u001b[39mshape), \u001b[38;5;28mreversed\u001b[39m(dst\u001b[38;5;241m.\u001b[39mshape), fillvalue\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     80\u001b[0m     ]):\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     82\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not broadcast input array \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     83\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m into shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdst\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     84\u001b[0m     squeeze_ndim \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m-\u001b[39m dst\u001b[38;5;241m.\u001b[39mndim\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m squeeze_ndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;66;03m# always succeeds because broadcast conition is checked.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (7818,) into shape (977,)"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "from kvikio.nvcomp_codec import NvCompBatchCodec\n",
    "from kvikio import defaults, CuFile\n",
    "import uproot\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import awkward as ak\n",
    "from uproot.models.RNTuple import _recursive_find\n",
    "\n",
    "def GPU_read_col_col_cluster_pages(in_ntuple, ncol, cluster_i, filehandle):\n",
    "    linklist = in_ntuple.page_list_envelopes.pagelinklist[cluster_i]\n",
    "    pagelist = linklist[ncol].pages if ncol < len(linklist) else []\n",
    "    dtype_byte = in_ntuple.column_records[ncol].type\n",
    "    dtype_str = uproot.const.rntuple_col_num_to_dtype_dict[dtype_byte]\n",
    "    \n",
    "    if dtype_str == \"switch\":\n",
    "        dtype = np.dtype([(\"index\", \"int64\"), (\"tag\", \"int32\")])\n",
    "    elif dtype_str == \"bit\":\n",
    "        dtype = np.dtype(\"bool\")\n",
    "    else:\n",
    "        dtype = np.dtype(dtype_str)\n",
    "    split = dtype_byte in uproot.const.rntuple_split_types\n",
    "\n",
    "\n",
    "    n_pages = len(pagelist)\n",
    "    output_buffers = []\n",
    "    compressed_buffers = []\n",
    "    futures = []\n",
    "\n",
    "    for page_desc in pagelist:\n",
    "        n_elements = page_desc.num_elements\n",
    "        loc = page_desc.locator\n",
    "        n_bytes = loc.num_bytes\n",
    "        isbit = dtype_str == \"bit\"\n",
    "        len_divider = 8 if isbit else 1\n",
    "        num_elements = n_elements\n",
    "        n_elements_toread = num_elements // dtype.itemsize\n",
    "        if isbit:\n",
    "            num_elements_toread = int(numpy.ceil(num_elements / 8))\n",
    "        elif dtype_str in (\"real32trunc\", \"real32quant\"):\n",
    "            num_elements_toread = int(numpy.ceil((num_elements * 4 * nbits) / 32))\n",
    "            dtype = numpy.dtype(\"uint8\")\n",
    "        else:\n",
    "            num_elements_toread = num_elements\n",
    "\n",
    "        uncomp_size = num_elements_toread * dtype.itemsize\n",
    "\n",
    "        \n",
    "        out_buff = cp.empty(n_elements_toread, dtype = dtype)\n",
    "\n",
    "\n",
    "        # Use locator to read page\n",
    "        \n",
    "        comp_buff = cp.empty(n_bytes - 9, dtype = \"b\")\n",
    "        fut = filehandle.pread(comp_buff,\n",
    "                              size = int(n_bytes - 9),\n",
    "                              file_offset = int(loc.offset + 9))\n",
    "\n",
    "\n",
    "        output_buffers.append(out_buff)\n",
    "        compressed_buffers.append(comp_buff)\n",
    "        futures.append(fut)\n",
    "        \n",
    "    for future in futures:\n",
    "        future.get()\n",
    "            \n",
    "    return (compressed_buffers, output_buffers, futures)\n",
    "    \n",
    "        \n",
    "    \n",
    "def GPU_read_col_clusters(in_ntuple, ncol, cluster_range, dtype_byte):\n",
    "    filepath = in_ntuple.file.source.file_path\n",
    "    compressed_buffers = []\n",
    "    output_buffers = []\n",
    "    futures = []\n",
    "    print(\"Reading column {}\".format(ncol))\n",
    "    with CuFile(filepath, \"rb\") as filehandle:\n",
    "        for i, cluster_i in enumerate(cluster_range):\n",
    "            (cluster_compressed_buffers,\n",
    "             cluster_output_buffers,\n",
    "             cluster_futures) = GPU_read_col_col_cluster_pages(in_ntuple,\n",
    "                                                                ncol,\n",
    "                                                                cluster_i,\n",
    "                                                                filehandle)\n",
    "            # Aggregate results\n",
    "            compressed_buffers.extend(cluster_compressed_buffers)\n",
    "            output_buffers.extend(cluster_output_buffers)\n",
    "            futures.extend(cluster_futures)\n",
    "\n",
    "    # Does not work.... futures maybe cannot be passed arbitrarily deep\n",
    "    # Wait for all reads to complete\n",
    "        # for fut in futures:\n",
    "        #     if not fut.done():\n",
    "        #         print(f\"Future not completed: {fut}\")\n",
    "        #         fut.get()  \n",
    "\n",
    "    return compressed_buffers, output_buffers\n",
    "    \n",
    "\n",
    "def GPU_read_cols(in_ntuple, columns, start_cluster_idx, stop_cluster_idx):\n",
    "    compressed_buffers = []\n",
    "    output_buffers = []\n",
    "    for key in columns:\n",
    "        if \"column\" in key and \"union\" not in key:\n",
    "            key_nr = int(key.split(\"-\")[1])\n",
    "            dtype_byte = in_ntuple.ntuple.column_records[key_nr].type\n",
    "            cluster_range = range(start_cluster_idx, stop_cluster_idx)\n",
    "            \n",
    "            compressed_buffers_col, output_buffers_col = GPU_read_col_clusters(in_ntuple,\n",
    "                                                                       key_nr,\n",
    "                                                                       cluster_range,\n",
    "                                                                       dtype_byte)\n",
    "            compressed_buffers.extend(compressed_buffers_col)\n",
    "            output_buffers.extend(output_buffers_col)\n",
    "            \n",
    "    #print(len(compressed_buffers), len(output_buffers))\n",
    "    #print(compressed_buffers, output_buffers)\n",
    "    return(compressed_buffers, output_buffers)\n",
    "            \n",
    "\n",
    "def Process_decompressed_content(in_ntuple, columns,\n",
    "                                 start_cluster_idx, stop_cluster_idx,\n",
    "                                 all_decompressed_content):\n",
    "    for key in columns:\n",
    "        n_pages = 0\n",
    "\n",
    "        if \"column\" in key and \"union\" not in key:\n",
    "            key_nr = int(key.split(\"-\")[1])\n",
    "            dtype_byte = in_ntuple.ntuple.column_records[key_nr].type\n",
    "            cluster_range = range(start_cluster_idx, stop_cluster_idx)\n",
    "            page_i = -1\n",
    "            \n",
    "            for i in cluster_range:\n",
    "                arrays = []\n",
    "                linklist = self.page_list_envelopes.pagelinklist[cluster_i]\n",
    "                pagelist = linklist[ncol].pages if ncol < len(linklist) else []\n",
    "                n_pages += len(pagelist)\n",
    "                dtype_byte = self.column_records[ncol].type\n",
    "                dtype_str = uproot.const.rntuple_col_num_to_dtype_dict[dtype_byte]\n",
    "                total_len = numpy.sum([desc.num_elements for desc in pagelist], dtype=int)\n",
    "                if dtype_str == \"switch\":\n",
    "                    dtype = numpy.dtype([(\"index\", \"int64\"), (\"tag\", \"int32\")])\n",
    "                elif dtype_str == \"bit\":\n",
    "                    dtype = numpy.dtype(\"bool\")\n",
    "                else:\n",
    "                    dtype = numpy.dtype(dtype_str)\n",
    "                res = cp.empty(total_len, dtype)\n",
    "                split = dtype_byte in uproot.const.rntuple_split_types\n",
    "                zigzag = dtype_byte in uproot.const.rntuple_zigzag_types\n",
    "                delta = dtype_byte in uproot.const.rntuple_delta_types\n",
    "                index = dtype_byte in uproot.const.rntuple_index_types\n",
    "                nbits = uproot.const.rntuple_col_num_to_size_dict[dtype_byte]\n",
    "                tracker = 0\n",
    "                cumsum = 0\n",
    "                for page_desc in pagelist:\n",
    "                    page_i += 1\n",
    "                    n_elements = page_desc.num_elements\n",
    "                    tracker_end = tracker + n_elements\n",
    "                    content = all_decompressed_content[i]\n",
    "\n",
    "                    loc = page_desc.locator\n",
    "                    context = {}\n",
    "                    # bool in RNTuple is always stored as bits\n",
    "                    isbit = dtype_str == \"bit\"\n",
    "                    len_divider = 8 if isbit else 1\n",
    "\n",
    "                    if split:\n",
    "                        content = content.view(cp.uint8)\n",
    "            \n",
    "                        if nbits == 16:\n",
    "                            # AAAAABBBBB needs to become\n",
    "                            # ABABABABAB\n",
    "                            res = cp.empty(len(content), cp.uint8)\n",
    "                            res[0::2] = content[len(res) * 0 // 2 : len(res) * 1 // 2]\n",
    "                            res[1::2] = content[len(res) * 1 // 2 : len(res) * 2 // 2]\n",
    "            \n",
    "                        elif nbits == 32:\n",
    "                            # AAAAABBBBBCCCCCDDDDD needs to become\n",
    "                            # ABCDABCDABCDABCDABCD\n",
    "                            res = cp.empty(len(content), cp.uint8)\n",
    "                            res[0::4] = content[len(res) * 0 // 4 : len(res) * 1 // 4]\n",
    "                            res[1::4] = content[len(res) * 1 // 4 : len(res) * 2 // 4]\n",
    "                            res[2::4] = content[len(res) * 2 // 4 : len(res) * 3 // 4]\n",
    "                            res[3::4] = content[len(res) * 3 // 4 : len(res) * 4 // 4]\n",
    "            \n",
    "                        elif nbits == 64:\n",
    "                            # AAAAABBBBBCCCCCDDDDDEEEEEFFFFFGGGGGHHHHH needs to become\n",
    "                            # ABCDEFGHABCDEFGHABCDEFGHABCDEFGHABCDEFGH\n",
    "                            res = cp.empty(len(content), cp.uint8)\n",
    "                            res[0::8] = content[len(res) * 0 // 8 : len(res) * 1 // 8]\n",
    "                            res[1::8] = content[len(res) * 1 // 8 : len(res) * 2 // 8]\n",
    "                            res[2::8] = content[len(res) * 2 // 8 : len(res) * 3 // 8]\n",
    "                            res[3::8] = content[len(res) * 3 // 8 : len(res) * 4 // 8]\n",
    "                            res[4::8] = content[len(res) * 4 // 8 : len(res) * 5 // 8]\n",
    "                            res[5::8] = content[len(res) * 5 // 8 : len(res) * 6 // 8]\n",
    "                            res[6::8] = content[len(res) * 6 // 8 : len(res) * 7 // 8]\n",
    "                            res[7::8] = content[len(res) * 7 // 8 : len(res) * 8 // 8]\n",
    "            \n",
    "                        content[:] = res.view(dtype)\n",
    "            \n",
    "                    if isbit:\n",
    "                        content[:] = (\n",
    "                            cp.unpackbits(content.view(dtype=numpy.uint8))\n",
    "                            .reshape(-1, 8)[:, ::-1]\n",
    "                            .reshape(-1)\n",
    "                        )\n",
    "                    content = content[:n_elements]\n",
    "                    res[tracker:tracker_end] = content\n",
    "\n",
    "                    if delta:\n",
    "                        res[tracker] -= cumsum\n",
    "                        cumsum += cp.sum(res[tracker:tracker_end])\n",
    "                    tracker = tracker_end\n",
    "\n",
    "                    if index:\n",
    "                        res = cp.insert(res, 0, 0)  # for offsets\n",
    "                    if zigzag:\n",
    "                        res = _from_zigzag(res)\n",
    "                    elif delta:\n",
    "                        res = cp.cumsum(res)\n",
    "\n",
    "                    arrays.append(res)\n",
    "        \n",
    "        # Check if column stores offset values for jagged arrays (splitindex64) (applies to cardinality cols too):\n",
    "        if dtype_byte in uproot.const.rntuple_delta_types:\n",
    "            # Extract the last offset values:\n",
    "            last_elements = [\n",
    "                arr[-1] for arr in arrays[:-1]\n",
    "            ]  # First value always zero, therefore skip first arr.\n",
    "            # Compute cumulative sum using itertools.accumulate:\n",
    "            last_offsets = list(accumulate(last_elements))\n",
    "            # Add the offsets to each array\n",
    "            for i in range(1, len(arrays)):\n",
    "                arrays[i] += last_offsets[i - 1]\n",
    "            # Remove the first element from every sub-array except for the first one:\n",
    "            arrays = [arrays[0]] + [arr[1:] for arr in arrays[1:]]\n",
    "\n",
    "        res = cp.concatenate(arrays, axis=0)\n",
    "\n",
    "        if pad_missing_element:\n",
    "            first_element_index = self.column_records[ncol].first_element_index\n",
    "            res = numpy.pad(res, (first_element_index, 0))\n",
    "                    \n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "def kvikuproot_open_RNTuple(in_ntuple_path, columns, classname, entry_start = 0, entry_stop = None):\n",
    "    in_ntuple = uproot.open(in_ntuple_path)[classname]\n",
    "    entry_stop = entry_stop or in_ntuple.ntuple.num_entries\n",
    "    \n",
    "    # Find clusters to read that contain data from entry_start to entry_stop\n",
    "    clusters = in_ntuple.ntuple.cluster_summaries\n",
    "    cluster_starts = np.array([c.num_first_entry for c in clusters])\n",
    "\n",
    "    start_cluster_idx = (\n",
    "        np.searchsorted(cluster_starts, entry_start, side=\"right\") - 1\n",
    "    )\n",
    "    stop_cluster_idx = np.searchsorted(cluster_starts, entry_stop, side=\"right\")\n",
    "    cluster_num_entries = np.sum(\n",
    "        [c.num_entries for c in clusters[start_cluster_idx:stop_cluster_idx]]\n",
    "    )\n",
    "\n",
    "    # Get form for requested columns\n",
    "    form = in_ntuple.to_akform().select_columns(\n",
    "        columns, prune_unions_and_records=False\n",
    "    )\n",
    "\n",
    "    # Only read columns mentioned in the awkward form\n",
    "    target_cols = []\n",
    "    container_dict = {}\n",
    "    _recursive_find(form, target_cols)\n",
    "\n",
    "    # Read all columns 'compressed' data\n",
    "    all_compressed_buffers, all_output_buffers = GPU_read_cols(in_ntuple,\n",
    "                                                             target_cols,\n",
    "                                                             start_cluster_idx,\n",
    "                                                             stop_cluster_idx)\n",
    "\n",
    "    # Decompression GPU\n",
    "    print(\"GPU decompression\")\n",
    "    codec = NvCompBatchCodec(\"zstd\")\n",
    "    all_decompressed_content = codec.decode_batch(all_compressed_buffers,\n",
    "                                                 all_output_buffers)\n",
    "\n",
    "    # Process decompressed data\n",
    "    # arrays = Process_decompressed_content(in_ntuple,\n",
    "                                          # target_cols,\n",
    "                                          # start_cluster_idx,\n",
    "                                          # stop_cluster_idx,\n",
    "                                          # all_decompressed_content)\n",
    "    \n",
    "\n",
    "    # Process decompressed data\n",
    "    # for key in target_cols:\n",
    "    #     if \"column\" in key and \"union\" not in key:\n",
    "    #         key_nr = int(key.split(\"-\")[1])\n",
    "    #         dtype_byte = in_ntuple.ntuple.column_records[key_nr].type\n",
    "    #         cluster_range = range(start_cluster_idx, stop_cluster_idx)\n",
    "    #         arrays = []\n",
    "    #         for i, cluster_i in enumerate(cluster_range):\n",
    "    #                 linklist = self.page_list_envelopes.pagelinklist[cluster_i]\n",
    "    #                 pagelist = linklist[ncol].pages if ncol < len(linklist) else []\n",
    "    #                 dtype_byte = self.column_records[ncol].type\n",
    "    #                 dtype_str = uproot.const.rntuple_col_num_to_dtype_dict[dtype_byte]\n",
    "    #                 total_len = numpy.sum([desc.num_elements for desc in pagelist], dtype=int)\n",
    "    #                 if dtype_str == \"switch\":\n",
    "    #                     dtype = numpy.dtype([(\"index\", \"int64\"), (\"tag\", \"int32\")])\n",
    "    #                 elif dtype_str == \"bit\":\n",
    "    #                     dtype = numpy.dtype(\"bool\")\n",
    "    #                 else:\n",
    "    #                     dtype = numpy.dtype(dtype_str)\n",
    "    #                 split = dtype_byte in uproot.const.rntuple_split_types\n",
    "    #                 zigzag = dtype_byte in uproot.const.rntuple_zigzag_types\n",
    "    #                 delta = dtype_byte in uproot.const.rntuple_delta_types\n",
    "    #                 index = dtype_byte in uproot.const.rntuple_index_types\n",
    "    #                 nbits = uproot.const.rntuple_col_num_to_size_dict[dtype_byte]\n",
    "    #                 tracker = 0\n",
    "    #                 cumsum = 0\n",
    "    #                 for page_desc in pagelist:\n",
    "    #                     n_elements = page_desc.num_elements\n",
    "    #                     tracker_end = tracker + n_elements\n",
    "    #                     self.read_pagedesc(\n",
    "    #                         res[tracker:tracker_end], page_desc, dtype_str, dtype, nbits, split\n",
    "    #                     )\n",
    "    #                     if delta:\n",
    "    #                         res[tracker] -= cumsum\n",
    "    #                         cumsum += cp.sum(res[tracker:tracker_end])\n",
    "    #                     tracker = tracker_end\n",
    "            \n",
    "    #                 if index:\n",
    "    #                     res = cp.insert(res, 0, 0)  # for offsets\n",
    "    #                 if zigzag:\n",
    "    #                     res = _from_zigzag(res)\n",
    "    #                 elif delta:\n",
    "    #                     res = cp.cumsum(res)\n",
    "\n",
    "                    \n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "    return 0\n",
    "\n",
    "path_rntuple = \"/home/fstrug/uscmshome/nobackup/GPU/kvikio_playground/TTToSemiLeptonic_UL18JMERNTuple-zstd.root\"\n",
    "cols = [\"Jet_pt\"]\n",
    "classname = \"Events\"\n",
    "kvikuproot_open_RNTuple(path_rntuple, cols, classname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f55a53-7ee3-464b-a35b-20945d03bde2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a33e86d0-ad8b-4ad2-9545-29f7bafacdd4",
   "metadata": {},
   "source": [
    "# Fluff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c64de4a-09e0-481e-92e9-bd274e5c8c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = cp.array([1], dtype = cp.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16c96d71-fa6d-48ca-bf5d-f4cf623012e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on ndarray in module cupy object:\n",
      "\n",
      "class ndarray(cupy._core.core._ndarray_base)\n",
      " |  ndarray(*args, _obj=None, _no_init=False, **kwargs)\n",
      " |  \n",
      " |  __init__(self, shape, dtype=float, memptr=None, strides=None, order='C')\n",
      " |  \n",
      " |  Multi-dimensional array on a CUDA device.\n",
      " |  \n",
      " |  This class implements a subset of methods of :class:`numpy.ndarray`.\n",
      " |  The difference is that this class allocates the array content on the\n",
      " |  current GPU device.\n",
      " |  \n",
      " |  Args:\n",
      " |      shape (tuple of ints): Length of axes.\n",
      " |      dtype: Data type. It must be an argument of :class:`numpy.dtype`.\n",
      " |      memptr (cupy.cuda.MemoryPointer): Pointer to the array content head.\n",
      " |      strides (tuple of ints or None): Strides of data in memory.\n",
      " |      order ({'C', 'F'}): Row-major (C-style) or column-major\n",
      " |          (Fortran-style) order.\n",
      " |  \n",
      " |  Attributes:\n",
      " |      base (None or cupy.ndarray): Base array from which this array is\n",
      " |          created as a view.\n",
      " |      data (cupy.cuda.MemoryPointer): Pointer to the array content head.\n",
      " |      ~ndarray.dtype(numpy.dtype): Dtype object of element type.\n",
      " |  \n",
      " |          .. seealso::\n",
      " |             `Data type objects (dtype)                <https://numpy.org/doc/stable/reference/arrays.dtypes.html>`_\n",
      " |      ~ndarray.size (int): Number of elements this array holds.\n",
      " |  \n",
      " |          This is equivalent to product over the shape tuple.\n",
      " |  \n",
      " |          .. seealso:: :attr:`numpy.ndarray.size`\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      ndarray\n",
      " |      cupy._core.core._ndarray_base\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __array_finalize__(self, obj)\n",
      " |      ndarray.__array_finalize__(self, obj)\n",
      " |  \n",
      " |  __init__(self, *args, **kwargs)\n",
      " |      ndarray.__init__(self, *args, **kwargs)\n",
      " |  \n",
      " |  __new__(cls, *args, _obj=None, _no_init=False, **kwargs)\n",
      " |      ndarray.__new__(cls, *args, _obj=None, _no_init=False, **kwargs)\n",
      " |  \n",
      " |  view(self, dtype=None, type=None)\n",
      " |      ndarray.view(self, dtype=None, type=None)\n",
      " |      Returns a view of the array.\n",
      " |      \n",
      " |              Args:\n",
      " |                  dtype: If this is different from the data type of the array, the\n",
      " |                      returned view reinterpret the memory sequence as an array of\n",
      " |                      this type.\n",
      " |      \n",
      " |              Returns:\n",
      " |                  cupy.ndarray: A view of the array. A reference to the original\n",
      " |                  array is stored at the :attr:`~ndarray.base` attribute.\n",
      " |      \n",
      " |              .. seealso:: :meth:`numpy.ndarray.view`\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from cupy._core.core._ndarray_base:\n",
      " |  \n",
      " |  __abs__(self, /)\n",
      " |      abs(self)\n",
      " |  \n",
      " |  __add__(self, value, /)\n",
      " |      Return self+value.\n",
      " |  \n",
      " |  __and__(self, value, /)\n",
      " |      Return self&value.\n",
      " |  \n",
      " |  __array__(...)\n",
      " |      _ndarray_base.__array__(self, dtype=None)\n",
      " |  \n",
      " |  __array_function__(...)\n",
      " |      _ndarray_base.__array_function__(self, func, types, args, kwargs)\n",
      " |  \n",
      " |  __array_ufunc__(...)\n",
      " |      _ndarray_base.__array_ufunc__(self, ufunc, method, *inputs, **kwargs)\n",
      " |      Apply unary or binary ufunc to this array\n",
      " |      \n",
      " |              If binary, only allow if second argument is another cupy ndarray or\n",
      " |              a number, i.e., raise ValueError instead of silently converting a\n",
      " |              numpy array.\n",
      " |  \n",
      " |  __bool__(self, /)\n",
      " |      True if self else False\n",
      " |  \n",
      " |  __bytes__(...)\n",
      " |      _ndarray_base.__bytes__(self)\n",
      " |  \n",
      " |  __complex__(...)\n",
      " |      _ndarray_base.__complex__(self)\n",
      " |  \n",
      " |  __copy__(...)\n",
      " |      _ndarray_base.__copy__(self)\n",
      " |  \n",
      " |  __deepcopy__(...)\n",
      " |      _ndarray_base.__deepcopy__(self, memo)\n",
      " |  \n",
      " |  __delitem__(self, key, /)\n",
      " |      Delete self[key].\n",
      " |  \n",
      " |  __divmod__(self, value, /)\n",
      " |      Return divmod(self, value).\n",
      " |  \n",
      " |  __dlpack__(...)\n",
      " |      _ndarray_base.__dlpack__(self, *, stream=None)\n",
      " |  \n",
      " |  __dlpack_device__(...)\n",
      " |      _ndarray_base.__dlpack_device__(self)\n",
      " |  \n",
      " |  __eq__(self, value, /)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __float__(self, /)\n",
      " |      float(self)\n",
      " |  \n",
      " |  __floordiv__(self, value, /)\n",
      " |      Return self//value.\n",
      " |  \n",
      " |  __format__(...)\n",
      " |      _ndarray_base.__format__(self, format_spec)\n",
      " |  \n",
      " |  __ge__(self, value, /)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __getitem__(...)\n",
      " |      x.__getitem__(y) <==> x[y]\n",
      " |      \n",
      " |      Supports both basic and advanced indexing.\n",
      " |      \n",
      " |      .. note::\n",
      " |      \n",
      " |          Currently, it does not support ``slices`` that consists of more\n",
      " |          than one boolean arrays\n",
      " |      \n",
      " |      .. note::\n",
      " |      \n",
      " |         CuPy handles out-of-bounds indices differently from NumPy.\n",
      " |         NumPy handles them by raising an error, but CuPy wraps around them.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |          >>> a = cupy.arange(3)\n",
      " |          >>> a[[1, 3]]\n",
      " |          array([1, 0])\n",
      " |  \n",
      " |  __gt__(self, value, /)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __iadd__(self, value, /)\n",
      " |      Return self+=value.\n",
      " |  \n",
      " |  __iand__(self, value, /)\n",
      " |      Return self&=value.\n",
      " |  \n",
      " |  __ifloordiv__(self, value, /)\n",
      " |      Return self//=value.\n",
      " |  \n",
      " |  __ilshift__(self, value, /)\n",
      " |      Return self<<=value.\n",
      " |  \n",
      " |  __imod__(self, value, /)\n",
      " |      Return self%=value.\n",
      " |  \n",
      " |  __imul__(self, value, /)\n",
      " |      Return self*=value.\n",
      " |  \n",
      " |  __int__(self, /)\n",
      " |      int(self)\n",
      " |  \n",
      " |  __invert__(self, /)\n",
      " |      ~self\n",
      " |  \n",
      " |  __ior__(self, value, /)\n",
      " |      Return self|=value.\n",
      " |  \n",
      " |  __ipow__(self, value, /)\n",
      " |      Return self**=value.\n",
      " |  \n",
      " |  __irshift__(self, value, /)\n",
      " |      Return self>>=value.\n",
      " |  \n",
      " |  __isub__(self, value, /)\n",
      " |      Return self-=value.\n",
      " |  \n",
      " |  __iter__(self, /)\n",
      " |      Implement iter(self).\n",
      " |  \n",
      " |  __itruediv__(self, value, /)\n",
      " |      Return self/=value.\n",
      " |  \n",
      " |  __ixor__(self, value, /)\n",
      " |      Return self^=value.\n",
      " |  \n",
      " |  __le__(self, value, /)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __len__(self, /)\n",
      " |      Return len(self).\n",
      " |  \n",
      " |  __lshift__(self, value, /)\n",
      " |      Return self<<value.\n",
      " |  \n",
      " |  __lt__(self, value, /)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __matmul__(self, value, /)\n",
      " |      Return self@value.\n",
      " |  \n",
      " |  __mod__(self, value, /)\n",
      " |      Return self%value.\n",
      " |  \n",
      " |  __mul__(self, value, /)\n",
      " |      Return self*value.\n",
      " |  \n",
      " |  __ne__(self, value, /)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __neg__(self, /)\n",
      " |      -self\n",
      " |  \n",
      " |  __or__(self, value, /)\n",
      " |      Return self|value.\n",
      " |  \n",
      " |  __pos__(self, /)\n",
      " |      +self\n",
      " |  \n",
      " |  __pow__(self, value, mod=None, /)\n",
      " |      Return pow(self, value, mod).\n",
      " |  \n",
      " |  __radd__(self, value, /)\n",
      " |      Return value+self.\n",
      " |  \n",
      " |  __rand__(self, value, /)\n",
      " |      Return value&self.\n",
      " |  \n",
      " |  __rdivmod__(self, value, /)\n",
      " |      Return divmod(value, self).\n",
      " |  \n",
      " |  __reduce__(...)\n",
      " |      _ndarray_base.__reduce__(self)\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __rfloordiv__(self, value, /)\n",
      " |      Return value//self.\n",
      " |  \n",
      " |  __rlshift__(self, value, /)\n",
      " |      Return value<<self.\n",
      " |  \n",
      " |  __rmatmul__(self, value, /)\n",
      " |      Return value@self.\n",
      " |  \n",
      " |  __rmod__(self, value, /)\n",
      " |      Return value%self.\n",
      " |  \n",
      " |  __rmul__(self, value, /)\n",
      " |      Return value*self.\n",
      " |  \n",
      " |  __ror__(self, value, /)\n",
      " |      Return value|self.\n",
      " |  \n",
      " |  __rpow__(self, value, mod=None, /)\n",
      " |      Return pow(value, self, mod).\n",
      " |  \n",
      " |  __rrshift__(self, value, /)\n",
      " |      Return value>>self.\n",
      " |  \n",
      " |  __rshift__(self, value, /)\n",
      " |      Return self>>value.\n",
      " |  \n",
      " |  __rsub__(self, value, /)\n",
      " |      Return value-self.\n",
      " |  \n",
      " |  __rtruediv__(self, value, /)\n",
      " |      Return value/self.\n",
      " |  \n",
      " |  __rxor__(self, value, /)\n",
      " |      Return value^self.\n",
      " |  \n",
      " |  __setitem__(...)\n",
      " |      x.__setitem__(slices, y) <==> x[slices] = y\n",
      " |      \n",
      " |      Supports both basic and advanced indexing.\n",
      " |      \n",
      " |      .. note::\n",
      " |      \n",
      " |          Currently, it does not support ``slices`` that consists of more\n",
      " |          than one boolean arrays\n",
      " |      \n",
      " |      .. note::\n",
      " |      \n",
      " |          CuPy handles out-of-bounds indices differently from NumPy when\n",
      " |          using integer array indexing.\n",
      " |          NumPy handles them by raising an error, but CuPy wraps around them.\n",
      " |      \n",
      " |          >>> import cupy\n",
      " |          >>> x = cupy.arange(3)\n",
      " |          >>> x[[1, 3]] = 10\n",
      " |          >>> x\n",
      " |          array([10, 10,  2])\n",
      " |      \n",
      " |      .. note::\n",
      " |      \n",
      " |          The behavior differs from NumPy when integer arrays in ``slices``\n",
      " |          reference the same location multiple times.\n",
      " |          In that case, the value that is actually stored is undefined.\n",
      " |      \n",
      " |          >>> import cupy\n",
      " |          >>> a = cupy.zeros((2,))\n",
      " |          >>> i = cupy.arange(10000) % 2\n",
      " |          >>> v = cupy.arange(10000).astype(cupy.float64)\n",
      " |          >>> a[i] = v\n",
      " |          >>> a  # doctest: +SKIP\n",
      " |          array([9150., 9151.])\n",
      " |      \n",
      " |          On the other hand, NumPy stores the value corresponding to the\n",
      " |          last index among the indices referencing duplicate locations.\n",
      " |      \n",
      " |          >>> import numpy\n",
      " |          >>> a_cpu = numpy.zeros((2,))\n",
      " |          >>> i_cpu = numpy.arange(10000) % 2\n",
      " |          >>> v_cpu = numpy.arange(10000).astype(numpy.float64)\n",
      " |          >>> a_cpu[i_cpu] = v_cpu\n",
      " |          >>> a_cpu\n",
      " |          array([9998., 9999.])\n",
      " |  \n",
      " |  __str__(self, /)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  __sub__(self, value, /)\n",
      " |      Return self-value.\n",
      " |  \n",
      " |  __truediv__(self, value, /)\n",
      " |      Return self/value.\n",
      " |  \n",
      " |  __xor__(self, value, /)\n",
      " |      Return self^value.\n",
      " |  \n",
      " |  all(...)\n",
      " |      _ndarray_base.all(self, axis=None, out=None, keepdims=False) -> _ndarray_base\n",
      " |  \n",
      " |  any(...)\n",
      " |      _ndarray_base.any(self, axis=None, out=None, keepdims=False) -> _ndarray_base\n",
      " |  \n",
      " |  argmax(...)\n",
      " |      _ndarray_base.argmax(self, axis=None, out=None, dtype=None, keepdims=False) -> _ndarray_base\n",
      " |      Returns the indices of the maximum along a given axis.\n",
      " |      \n",
      " |              .. note::\n",
      " |                 ``dtype`` and ``keepdim`` arguments are specific to CuPy. They are\n",
      " |                 not in NumPy.\n",
      " |      \n",
      " |              .. note::\n",
      " |                 ``axis`` argument accepts a tuple of ints, but this is specific to\n",
      " |                 CuPy. NumPy does not support it.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                 :func:`cupy.argmax` for full documentation,\n",
      " |                 :meth:`numpy.ndarray.argmax`\n",
      " |  \n",
      " |  argmin(...)\n",
      " |      _ndarray_base.argmin(self, axis=None, out=None, dtype=None, keepdims=False) -> _ndarray_base\n",
      " |      Returns the indices of the minimum along a given axis.\n",
      " |      \n",
      " |              .. note::\n",
      " |                 ``dtype`` and ``keepdim`` arguments are specific to CuPy. They are\n",
      " |                 not in NumPy.\n",
      " |      \n",
      " |              .. note::\n",
      " |                 ``axis`` argument accepts a tuple of ints, but this is specific to\n",
      " |                 CuPy. NumPy does not support it.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                 :func:`cupy.argmin` for full documentation,\n",
      " |                 :meth:`numpy.ndarray.argmin`\n",
      " |  \n",
      " |  argpartition(...)\n",
      " |      _ndarray_base.argpartition(self, kth, axis=-1) -> _ndarray_base\n",
      " |      Returns the indices that would partially sort an array.\n",
      " |      \n",
      " |              Args:\n",
      " |                  kth (int or sequence of ints): Element index to partition by. If\n",
      " |                      supplied with a sequence of k-th it will partition all elements\n",
      " |                      indexed by k-th of them into their sorted position at once.\n",
      " |                  axis (int or None): Axis along which to sort. Default is -1, which\n",
      " |                      means sort along the last axis. If None is supplied, the array\n",
      " |                      is flattened before sorting.\n",
      " |      \n",
      " |              Returns:\n",
      " |                  cupy.ndarray: Array of the same type and shape as ``a``.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                  :func:`cupy.argpartition` for full documentation,\n",
      " |                  :meth:`numpy.ndarray.argpartition`\n",
      " |  \n",
      " |  argsort(...)\n",
      " |      _ndarray_base.argsort(self, axis=-1) -> _ndarray_base\n",
      " |      Returns the indices that would sort an array with stable sorting\n",
      " |      \n",
      " |              Args:\n",
      " |                  axis (int or None): Axis along which to sort. Default is -1, which\n",
      " |                      means sort along the last axis. If None is supplied, the array\n",
      " |                      is flattened before sorting.\n",
      " |      \n",
      " |              Returns:\n",
      " |                  cupy.ndarray: Array of indices that sort the array.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                  :func:`cupy.argsort` for full documentation,\n",
      " |                  :meth:`numpy.ndarray.argsort`\n",
      " |  \n",
      " |  astype(...)\n",
      " |      _ndarray_base.astype(self, dtype, order=u'K', casting=None, subok=None, copy=True) -> _ndarray_base\n",
      " |      Casts the array to given data type.\n",
      " |      \n",
      " |              Args:\n",
      " |                  dtype: Type specifier.\n",
      " |                  order ({'C', 'F', 'A', 'K'}): Row-major (C-style) or column-major\n",
      " |                      (Fortran-style) order.\n",
      " |                      When ``order`` is 'A', it uses 'F' if ``a`` is column-major and\n",
      " |                      uses 'C' otherwise.\n",
      " |                      And when ``order`` is 'K', it keeps strides as closely as\n",
      " |                      possible.\n",
      " |                  copy (bool): If it is False and no cast happens, then this method\n",
      " |                      returns the array itself. Otherwise, a copy is returned.\n",
      " |      \n",
      " |              Returns:\n",
      " |                  If ``copy`` is False and no cast is required, then the array itself\n",
      " |                  is returned. Otherwise, it returns a (possibly casted) copy of the\n",
      " |                  array.\n",
      " |      \n",
      " |              .. note::\n",
      " |                 This method currently does not support ``casting``, and ``subok``\n",
      " |                 arguments.\n",
      " |      \n",
      " |              .. seealso:: :meth:`numpy.ndarray.astype`\n",
      " |  \n",
      " |  choose(...)\n",
      " |      _ndarray_base.choose(self, choices, out=None, mode=u'raise')\n",
      " |  \n",
      " |  clip(...)\n",
      " |      _ndarray_base.clip(self, min=None, max=None, out=None) -> _ndarray_base\n",
      " |      Returns an array with values limited to [min, max].\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                 :func:`cupy.clip` for full documentation,\n",
      " |                 :meth:`numpy.ndarray.clip`\n",
      " |  \n",
      " |  compress(...)\n",
      " |      _ndarray_base.compress(self, condition, axis=None, out=None) -> _ndarray_base\n",
      " |      Returns selected slices of this array along given axis.\n",
      " |      \n",
      " |              .. warning::\n",
      " |      \n",
      " |                  This function may synchronize the device.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                 :func:`cupy.compress` for full documentation,\n",
      " |                 :meth:`numpy.ndarray.compress`\n",
      " |  \n",
      " |  conj(...)\n",
      " |      _ndarray_base.conj(self) -> _ndarray_base\n",
      " |  \n",
      " |  conjugate(...)\n",
      " |      _ndarray_base.conjugate(self) -> _ndarray_base\n",
      " |  \n",
      " |  copy(...)\n",
      " |      _ndarray_base.copy(self, order=u'C') -> _ndarray_base\n",
      " |      Returns a copy of the array.\n",
      " |      \n",
      " |              This method makes a copy of a given array in the current device.\n",
      " |              Even when a given array is located in another device, you can copy it\n",
      " |              to the current device.\n",
      " |      \n",
      " |              Args:\n",
      " |                  order ({'C', 'F', 'A', 'K'}): Row-major (C-style) or column-major\n",
      " |                      (Fortran-style) order.\n",
      " |                      When ``order`` is 'A', it uses 'F' if ``a`` is column-major and\n",
      " |                      uses 'C' otherwise.\n",
      " |                      And when `order` is 'K', it keeps strides as closely as\n",
      " |                      possible.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                 :func:`cupy.copy` for full documentation,\n",
      " |                 :meth:`numpy.ndarray.copy`\n",
      " |  \n",
      " |  cumprod(...)\n",
      " |      _ndarray_base.cumprod(self, axis=None, dtype=None, out=None) -> _ndarray_base\n",
      " |      Returns the cumulative product of an array along a given axis.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                 :func:`cupy.cumprod` for full documentation,\n",
      " |                 :meth:`numpy.ndarray.cumprod`\n",
      " |  \n",
      " |  cumsum(...)\n",
      " |      _ndarray_base.cumsum(self, axis=None, dtype=None, out=None) -> _ndarray_base\n",
      " |      Returns the cumulative sum of an array along a given axis.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                 :func:`cupy.cumsum` for full documentation,\n",
      " |                 :meth:`numpy.ndarray.cumsum`\n",
      " |  \n",
      " |  diagonal(...)\n",
      " |      _ndarray_base.diagonal(self, offset=0, axis1=0, axis2=1) -> _ndarray_base\n",
      " |      Returns a view of the specified diagonals.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                 :func:`cupy.diagonal` for full documentation,\n",
      " |                 :meth:`numpy.ndarray.diagonal`\n",
      " |  \n",
      " |  dot(...)\n",
      " |      _ndarray_base.dot(self, _ndarray_base b, _ndarray_base out=None)\n",
      " |      Returns the dot product with given array.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                 :func:`cupy.dot` for full documentation,\n",
      " |                 :meth:`numpy.ndarray.dot`\n",
      " |  \n",
      " |  dump(...)\n",
      " |      _ndarray_base.dump(self, file)\n",
      " |      Dumps a pickle of the array to a file.\n",
      " |      \n",
      " |              Dumped file can be read back to :class:`cupy.ndarray` by\n",
      " |              :func:`cupy.load`.\n",
      " |  \n",
      " |  dumps(...)\n",
      " |      _ndarray_base.dumps(self) -> bytes\n",
      " |      Dumps a pickle of the array to a string.\n",
      " |  \n",
      " |  fill(...)\n",
      " |      _ndarray_base.fill(self, value)\n",
      " |      Fills the array with a scalar value.\n",
      " |      \n",
      " |              Args:\n",
      " |                  value: A scalar value to fill the array content.\n",
      " |      \n",
      " |              .. seealso:: :meth:`numpy.ndarray.fill`\n",
      " |  \n",
      " |  flatten(...)\n",
      " |      _ndarray_base.flatten(self, order=u'C') -> _ndarray_base\n",
      " |      Returns a copy of the array flatten into one dimension.\n",
      " |      \n",
      " |              Args:\n",
      " |                  order ({'C', 'F', 'A', 'K'}):\n",
      " |                      'C' means to flatten in row-major (C-style) order.\n",
      " |                      'F' means to flatten in column-major (Fortran-\n",
      " |                      style) order. 'A' means to flatten in column-major\n",
      " |                      order if `self` is Fortran *contiguous* in memory,\n",
      " |                      row-major order otherwise. 'K' means to flatten\n",
      " |                      `self` in the order the elements occur in memory.\n",
      " |                      The default is 'C'.\n",
      " |      \n",
      " |              Returns:\n",
      " |                  cupy.ndarray: A copy of the array with one dimension.\n",
      " |      \n",
      " |              .. seealso:: :meth:`numpy.ndarray.flatten`\n",
      " |  \n",
      " |  get(...)\n",
      " |      _ndarray_base.get(self, stream=None, order=u'C', out=None, blocking=True)\n",
      " |      Returns a copy of the array on host memory.\n",
      " |      \n",
      " |              Args:\n",
      " |                  stream (cupy.cuda.Stream): CUDA stream object. If given, the\n",
      " |                      stream is used to perform the copy. Otherwise, the current\n",
      " |                      stream is used.\n",
      " |                  order ({'C', 'F', 'A'}): The desired memory layout of the host\n",
      " |                      array. When ``order`` is 'A', it uses 'F' if the array is\n",
      " |                      fortran-contiguous and 'C' otherwise. The ``order`` will be\n",
      " |                      ignored if ``out`` is specified.\n",
      " |                  out (numpy.ndarray): Output array. In order to enable asynchronous\n",
      " |                      copy, the underlying memory should be a pinned memory.\n",
      " |                  blocking (bool): If set to ``False``, the copy runs asynchronously\n",
      " |                      on the given (if given) or current stream, and users are\n",
      " |                      responsible for ensuring the stream order. Default is ``True``,\n",
      " |                      so the copy is synchronous (with respect to the host).\n",
      " |      \n",
      " |              Returns:\n",
      " |                  numpy.ndarray: Copy of the array on host memory.\n",
      " |  \n",
      " |  item(...)\n",
      " |      _ndarray_base.item(self)\n",
      " |      Converts the array with one element to a Python scalar\n",
      " |      \n",
      " |              Returns:\n",
      " |                  int or float or complex: The element of the array.\n",
      " |      \n",
      " |              .. seealso:: :meth:`numpy.ndarray.item`\n",
      " |  \n",
      " |  max(...)\n",
      " |      _ndarray_base.max(self, axis=None, out=None, keepdims=False) -> _ndarray_base\n",
      " |      Returns the maximum along a given axis.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                 :func:`cupy.amax` for full documentation,\n",
      " |                 :meth:`numpy.ndarray.max`\n",
      " |  \n",
      " |  mean(...)\n",
      " |      _ndarray_base.mean(self, axis=None, dtype=None, out=None, keepdims=False) -> _ndarray_base\n",
      " |      Returns the mean along a given axis.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                 :func:`cupy.mean` for full documentation,\n",
      " |                 :meth:`numpy.ndarray.mean`\n",
      " |  \n",
      " |  min(...)\n",
      " |      _ndarray_base.min(self, axis=None, out=None, keepdims=False) -> _ndarray_base\n",
      " |      Returns the minimum along a given axis.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                 :func:`cupy.amin` for full documentation,\n",
      " |                 :meth:`numpy.ndarray.min`\n",
      " |  \n",
      " |  nonzero(...)\n",
      " |      _ndarray_base.nonzero(self) -> tuple\n",
      " |      Return the indices of the elements that are non-zero.\n",
      " |      \n",
      " |              Returned Array is containing the indices of the non-zero elements\n",
      " |              in that dimension.\n",
      " |      \n",
      " |              Returns:\n",
      " |                  tuple of arrays: Indices of elements that are non-zero.\n",
      " |      \n",
      " |              .. warning::\n",
      " |      \n",
      " |                  This function may synchronize the device.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                  :func:`numpy.nonzero`\n",
      " |  \n",
      " |  partition(...)\n",
      " |      _ndarray_base.partition(self, kth, int axis=-1)\n",
      " |      Partitions an array.\n",
      " |      \n",
      " |              Args:\n",
      " |                  kth (int or sequence of ints): Element index to partition by. If\n",
      " |                      supplied with a sequence of k-th it will partition all elements\n",
      " |                      indexed by k-th of them into their sorted position at once.\n",
      " |      \n",
      " |                  axis (int): Axis along which to sort. Default is -1, which means\n",
      " |                      sort along the last axis.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                  :func:`cupy.partition` for full documentation,\n",
      " |                  :meth:`numpy.ndarray.partition`\n",
      " |  \n",
      " |  prod(...)\n",
      " |      _ndarray_base.prod(self, axis=None, dtype=None, out=None, keepdims=None) -> _ndarray_base\n",
      " |      Returns the product along a given axis.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                 :func:`cupy.prod` for full documentation,\n",
      " |                 :meth:`numpy.ndarray.prod`\n",
      " |  \n",
      " |  ptp(...)\n",
      " |      _ndarray_base.ptp(self, axis=None, out=None, keepdims=False) -> _ndarray_base\n",
      " |      Returns (maximum - minimum) along a given axis.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                 :func:`cupy.ptp` for full documentation,\n",
      " |                 :meth:`numpy.ndarray.ptp`\n",
      " |  \n",
      " |  put(...)\n",
      " |      _ndarray_base.put(self, indices, values, mode=u'wrap')\n",
      " |      Replaces specified elements of an array with given values.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                 :func:`cupy.put` for full documentation,\n",
      " |                 :meth:`numpy.ndarray.put`\n",
      " |  \n",
      " |  ravel(...)\n",
      " |      _ndarray_base.ravel(self, order=u'C') -> _ndarray_base\n",
      " |      Returns an array flattened into one dimension.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                 :func:`cupy.ravel` for full documentation,\n",
      " |                 :meth:`numpy.ndarray.ravel`\n",
      " |  \n",
      " |  reduced_view(...)\n",
      " |      _ndarray_base.reduced_view(self, dtype=None) -> _ndarray_base\n",
      " |      Returns a view of the array with minimum number of dimensions.\n",
      " |      \n",
      " |              Args:\n",
      " |                  dtype: (Deprecated) Data type specifier.\n",
      " |                      If it is given, then the memory\n",
      " |                      sequence is reinterpreted as the new type.\n",
      " |      \n",
      " |              Returns:\n",
      " |                  cupy.ndarray: A view of the array with reduced dimensions.\n",
      " |  \n",
      " |  repeat(...)\n",
      " |      _ndarray_base.repeat(self, repeats, axis=None)\n",
      " |      Returns an array with repeated arrays along an axis.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                  :func:`cupy.repeat` for full documentation,\n",
      " |                  :meth:`numpy.ndarray.repeat`\n",
      " |  \n",
      " |  reshape(...)\n",
      " |      _ndarray_base.reshape(self, *shape, order=u'C')\n",
      " |      Returns an array of a different shape and the same content.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                 :func:`cupy.reshape` for full documentation,\n",
      " |                 :meth:`numpy.ndarray.reshape`\n",
      " |  \n",
      " |  round(...)\n",
      " |      _ndarray_base.round(self, decimals=0, out=None) -> _ndarray_base\n",
      " |      Returns an array with values rounded to the given number of decimals.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                 :func:`cupy.around` for full documentation,\n",
      " |                 :meth:`numpy.ndarray.round`\n",
      " |  \n",
      " |  scatter_add(...)\n",
      " |      _ndarray_base.scatter_add(self, slices, value)\n",
      " |      Adds given values to specified elements of an array.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                  :func:`cupyx.scatter_add` for full documentation.\n",
      " |  \n",
      " |  scatter_max(...)\n",
      " |      _ndarray_base.scatter_max(self, slices, value)\n",
      " |      Stores a maximum value of elements specified by indices to an array.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                  :func:`cupyx.scatter_max` for full documentation.\n",
      " |  \n",
      " |  scatter_min(...)\n",
      " |      _ndarray_base.scatter_min(self, slices, value)\n",
      " |      Stores a minimum value of elements specified by indices to an array.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                  :func:`cupyx.scatter_min` for full documentation.\n",
      " |  \n",
      " |  searchsorted(...)\n",
      " |      _ndarray_base.searchsorted(self, v, side=u'left', sorter=None)\n",
      " |      Finds indices where elements of v should be inserted to maintain order.\n",
      " |      \n",
      " |              For full documentation, see :func:`cupy.searchsorted`\n",
      " |      \n",
      " |              Returns:\n",
      " |      \n",
      " |              .. seealso:: :func:`numpy.searchsorted`\n",
      " |  \n",
      " |  set(...)\n",
      " |      _ndarray_base.set(self, arr, stream=None)\n",
      " |      Copies an array on the host memory to :class:`cupy.ndarray`.\n",
      " |      \n",
      " |              Args:\n",
      " |                  arr (numpy.ndarray): The source array on the host memory.\n",
      " |                  stream (cupy.cuda.Stream): CUDA stream object. If given, the\n",
      " |                      stream is used to perform the copy. Otherwise, the current\n",
      " |                      stream is used.\n",
      " |  \n",
      " |  sort(...)\n",
      " |      _ndarray_base.sort(self, int axis=-1)\n",
      " |      Sort an array, in-place with a stable sorting algorithm.\n",
      " |      \n",
      " |              Args:\n",
      " |                  axis (int): Axis along which to sort. Default is -1, which means\n",
      " |                      sort along the last axis.\n",
      " |      \n",
      " |              .. note::\n",
      " |                 For its implementation reason, ``ndarray.sort`` currently supports\n",
      " |                 only arrays with their own data, and does not support ``kind`` and\n",
      " |                 ``order`` parameters that ``numpy.ndarray.sort`` does support.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                  :func:`cupy.sort` for full documentation,\n",
      " |                  :meth:`numpy.ndarray.sort`\n",
      " |  \n",
      " |  squeeze(...)\n",
      " |      _ndarray_base.squeeze(self, axis=None) -> _ndarray_base\n",
      " |      Returns a view with size-one axes removed.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                 :func:`cupy.squeeze` for full documentation,\n",
      " |                 :meth:`numpy.ndarray.squeeze`\n",
      " |  \n",
      " |  std(...)\n",
      " |      _ndarray_base.std(self, axis=None, dtype=None, out=None, ddof=0, keepdims=False) -> _ndarray_base\n",
      " |      Returns the standard deviation along a given axis.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                 :func:`cupy.std` for full documentation,\n",
      " |                 :meth:`numpy.ndarray.std`\n",
      " |  \n",
      " |  sum(...)\n",
      " |      _ndarray_base.sum(self, axis=None, dtype=None, out=None, keepdims=False) -> _ndarray_base\n",
      " |      Returns the sum along a given axis.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                 :func:`cupy.sum` for full documentation,\n",
      " |                 :meth:`numpy.ndarray.sum`\n",
      " |  \n",
      " |  swapaxes(...)\n",
      " |      _ndarray_base.swapaxes(self, Py_ssize_t axis1, Py_ssize_t axis2) -> _ndarray_base\n",
      " |      Returns a view of the array with two axes swapped.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                 :func:`cupy.swapaxes` for full documentation,\n",
      " |                 :meth:`numpy.ndarray.swapaxes`\n",
      " |  \n",
      " |  take(...)\n",
      " |      _ndarray_base.take(self, indices, axis=None, out=None) -> _ndarray_base\n",
      " |      Returns an array of elements at given indices along the axis.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                 :func:`cupy.take` for full documentation,\n",
      " |                 :meth:`numpy.ndarray.take`\n",
      " |  \n",
      " |  toDlpack(...)\n",
      " |      _ndarray_base.toDlpack(self)\n",
      " |      Zero-copy conversion to a DLPack tensor.\n",
      " |      \n",
      " |              DLPack is a open in memory tensor structure proposed in this\n",
      " |              repository: `dmlc/dlpack <https://github.com/dmlc/dlpack>`_.\n",
      " |      \n",
      " |              This function returns a :class:`PyCapsule` object which contains a\n",
      " |              pointer to a DLPack tensor converted from the own ndarray. This\n",
      " |              function does not copy the own data to the output DLpack tensor\n",
      " |              but it shares the pointer which is pointing to the same memory region\n",
      " |              for the data.\n",
      " |      \n",
      " |              Returns:\n",
      " |                  dltensor (:class:`PyCapsule`): Output DLPack tensor which is\n",
      " |                  encapsulated in a :class:`PyCapsule` object.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |      \n",
      " |                  :meth:`~cupy.fromDlpack` is a method for zero-copy conversion from\n",
      " |                  a DLPack tensor (which is encapsulated in a :class:`PyCapsule`\n",
      " |                  object) to a :class:`ndarray`\n",
      " |      \n",
      " |              .. warning::\n",
      " |      \n",
      " |                  As of the DLPack v0.3 specification, it is (implicitly) assumed\n",
      " |                  that the user is responsible to ensure the Producer and the\n",
      " |                  Consumer are operating on the same stream. This requirement might\n",
      " |                  be relaxed/changed in a future DLPack version.\n",
      " |      \n",
      " |              .. admonition:: Example\n",
      " |      \n",
      " |                  >>> import cupy\n",
      " |                  >>> array1 = cupy.array([0, 1, 2], dtype=cupy.float32)\n",
      " |                  >>> dltensor = array1.toDlpack()\n",
      " |                  >>> array2 = cupy.fromDlpack(dltensor)\n",
      " |                  >>> cupy.testing.assert_array_equal(array1, array2)\n",
      " |  \n",
      " |  tobytes(...)\n",
      " |      _ndarray_base.tobytes(self, order=u'C') -> bytes\n",
      " |      Turns the array into a Python bytes object.\n",
      " |  \n",
      " |  tofile(...)\n",
      " |      _ndarray_base.tofile(self, fid, sep=u'', format=u'%s')\n",
      " |      Writes the array to a file.\n",
      " |      \n",
      " |              .. seealso:: :meth:`numpy.ndarray.tofile`\n",
      " |  \n",
      " |  tolist(...)\n",
      " |      _ndarray_base.tolist(self)\n",
      " |      Converts the array to a (possibly nested) Python list.\n",
      " |      \n",
      " |              Returns:\n",
      " |                  list: The possibly nested Python list of array elements.\n",
      " |      \n",
      " |              .. seealso:: :meth:`numpy.ndarray.tolist`\n",
      " |  \n",
      " |  trace(...)\n",
      " |      _ndarray_base.trace(self, offset=0, axis1=0, axis2=1, dtype=None, out=None) -> _ndarray_base\n",
      " |      Returns the sum along diagonals of the array.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                 :func:`cupy.trace` for full documentation,\n",
      " |                 :meth:`numpy.ndarray.trace`\n",
      " |  \n",
      " |  transpose(...)\n",
      " |      _ndarray_base.transpose(self, *axes)\n",
      " |      Returns a view of the array with axes permuted.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                 :func:`cupy.transpose` for full documentation,\n",
      " |                 :meth:`numpy.ndarray.reshape`\n",
      " |  \n",
      " |  var(...)\n",
      " |      _ndarray_base.var(self, axis=None, dtype=None, out=None, ddof=0, keepdims=False) -> _ndarray_base\n",
      " |      Returns the variance along a given axis.\n",
      " |      \n",
      " |              .. seealso::\n",
      " |                 :func:`cupy.var` for full documentation,\n",
      " |                 :meth:`numpy.ndarray.var`\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from cupy._core.core._ndarray_base:\n",
      " |  \n",
      " |  __class_getitem__(...)\n",
      " |      _ndarray_base.__class_getitem__(type cls, tuple item)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from cupy._core.core._ndarray_base:\n",
      " |  \n",
      " |  T\n",
      " |      Shape-reversed view of the array.\n",
      " |      \n",
      " |      If ndim < 2, then this is just a reference to the array itself.\n",
      " |  \n",
      " |  __cuda_array_interface__\n",
      " |  \n",
      " |  base\n",
      " |  \n",
      " |  cstruct\n",
      " |      C representation of the array.\n",
      " |      \n",
      " |      This property is used for sending an array to CUDA kernels. The type of\n",
      " |      returned C structure is different for different dtypes and ndims. The\n",
      " |      definition of C type is written in ``cupy/carray.cuh``.\n",
      " |  \n",
      " |  data\n",
      " |  \n",
      " |  device\n",
      " |      CUDA device on which this array resides.\n",
      " |  \n",
      " |  dtype\n",
      " |  \n",
      " |  flags\n",
      " |      Object containing memory-layout information.\n",
      " |      \n",
      " |      It only contains ``c_contiguous``, ``f_contiguous``, and ``owndata``\n",
      " |      attributes. All of these are read-only. Accessing by indexes is also\n",
      " |      supported.\n",
      " |      \n",
      " |      .. seealso:: :attr:`numpy.ndarray.flags`\n",
      " |  \n",
      " |  flat\n",
      " |  \n",
      " |  imag\n",
      " |  \n",
      " |  itemsize\n",
      " |      Size of each element in bytes.\n",
      " |      \n",
      " |      .. seealso:: :attr:`numpy.ndarray.itemsize`\n",
      " |  \n",
      " |  nbytes\n",
      " |      Total size of all elements in bytes.\n",
      " |      \n",
      " |      It does not count skips between elements.\n",
      " |      \n",
      " |      .. seealso:: :attr:`numpy.ndarray.nbytes`\n",
      " |  \n",
      " |  ndim\n",
      " |      Number of dimensions.\n",
      " |      \n",
      " |      ``a.ndim`` is equivalent to ``len(a.shape)``.\n",
      " |      \n",
      " |      .. seealso:: :attr:`numpy.ndarray.ndim`\n",
      " |  \n",
      " |  real\n",
      " |  \n",
      " |  shape\n",
      " |      Lengths of axes.\n",
      " |      \n",
      " |      Setter of this property involves reshaping without copy. If the array\n",
      " |      cannot be reshaped without copy, it raises an exception.\n",
      " |      \n",
      " |      .. seealso: :attr:`numpy.ndarray.shape`\n",
      " |  \n",
      " |  size\n",
      " |  \n",
      " |  strides\n",
      " |      Strides of axes in bytes.\n",
      " |      \n",
      " |      .. seealso:: :attr:`numpy.ndarray.strides`\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from cupy._core.core._ndarray_base:\n",
      " |  \n",
      " |  __array_priority__ = 100\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  __pyx_vtable__ = <capsule object NULL>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee88281c-a624-4c3f-b536-18875c7ce84b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-kvikio-cuda12.5-py3.11]",
   "language": "python",
   "name": "conda-env-.conda-kvikio-cuda12.5-py3.11-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
